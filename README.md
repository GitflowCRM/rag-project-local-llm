# Lang-Gemma-v2: RAG Backend with Qdrant, NestJS, and Local LLM

## Overview
This project is a Retrieval-Augmented Generation (RAG) backend built with NestJS, PostgreSQL, Qdrant (vector DB), and a local LLM. It allows you to ingest user events, generate embeddings, store them in Qdrant, and answer natural language questions using a combination of semantic search and LLM generation.

---

## 1. Feeding Events (Add Data)

Events are stored in PostgreSQL. You can add events via a REST endpoint.

### Example Event JSON
```json
{
  "user_id": "history",
  "event_type": "fact",
  "event_data": {
    "fact": "The Great Pyramid of Giza was built around 2560 BCE and was the tallest man-made structure for over 3,800 years.",
    "topic": "Ancient Egypt",
    "source": "historical records",
    "category": "architecture"
  },
  "event_timestamp": "2025-06-18T13:22:14.154Z"
}
```

### Add an Event (Example curl)
```bash
curl --location 'http://localhost:3000/events' \
--header 'Content-Type: application/json' \
--data '{
    "user_id": "history",
    "event_type": "fact",
    "event_data": {"fact": "The Great Pyramid of Giza was built around 2560 BCE and was the tallest man-made structure for over 3,800 years.", "topic": "Ancient Egypt", "source": "historical records", "category": "architecture"},
    "event_timestamp": "2025-06-18T13:22:14.154Z"
}'
```

---

## 2. Ingest Events to Qdrant (Vector DB)

After adding events, you need to ingest them into Qdrant. This will generate embeddings and store them as vectors.

### Ingest All New Events
```bash
curl --location 'http://localhost:3000/qdrant/ingest' \
--header 'Content-Type: application/json' \
--data '{
    "collection": "events"
}'
```
- Only events not yet ingested (where `ingested_at` is null) will be processed.

---

## 3. Test Semantic Search

You can search for similar events using a semantic query.

### Example Semantic Search
```bash
curl --location 'http://localhost:3000/qdrant/semantic-search' \
--header 'Content-Type: application/json' \
--data '{
    "collection": "events",
    "query": "What is the oldest pyramid in Egypt?",
    "top": 3
}'
```
- Returns the most relevant events (with payload and similarity score).

---

## 4. Retrieval-Augmented Generation (RAG) - Ask Questions

You can ask natural language questions and get answers generated by the LLM, grounded in your event data.

### Example RAG Query
```bash
curl --location 'http://localhost:3000/qdrant/rag-search' \
--header 'Content-Type: application/json' \
--data '{
    "collection": "events",
    "query": "When was the Great Pyramid built and why was it significant?",
    "top": 3
}'
```
- The response includes your query, the generated answer, and the source facts used.

---

## 5. Testing LLM Hallucination (Out-of-Knowledge-Base)

Try asking questions not covered by your data to verify the LLM does not hallucinate:

```bash
curl --location 'http://localhost:3000/qdrant/rag-search' \
--header 'Content-Type: application/json' \
--data '{
    "collection": "events",
    "query": "What will be the next major archaeological discovery in Egypt?",
    "top": 3
}'
```
- The answer should indicate that there is not enough information in the facts to answer the question.

---

## 6. Useful Endpoints

- `POST /events` — Add a new event
- `POST /qdrant/ingest` — Ingest new events to Qdrant
- `POST /qdrant/semantic-search` — Semantic search for similar events
- `POST /qdrant/rag-search` — Retrieval-augmented question answering

---

## 7. Running the System

- Make sure PostgreSQL and Qdrant are running (see `docker-compose.yml`).
- Start the NestJS server:
  ```bash
  bun start
  ```
- Use the above curl commands to add, ingest, and query data.

---

## 8. Notes
- Embeddings are generated using OpenAI or HuggingFace (see `EmbeddingsService`).
- LLM answers are generated using your local LLM (see `LlmService`).
- All endpoints are documented with Swagger (visit `/api` if enabled).

---

For more details, see the code in the `src/` directory or ask for help!
